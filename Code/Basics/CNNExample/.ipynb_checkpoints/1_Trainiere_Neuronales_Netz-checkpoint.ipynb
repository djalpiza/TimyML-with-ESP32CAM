{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training eines neuronalen Netzes\n",
    "\n",
    "In diesem Skript wird das Training eines neuronalen Netzes durchgeführt. Dazu werden die folgende Schritte der Reihe nach durchgeführt:\n",
    "\n",
    "0. Vorbereitung (Laden der Bibliotheken und Einstellungen\n",
    "1. Laden der Bilder\n",
    "2. Erzeugen Trainingsdaten & Testdaten\n",
    "3. Definition und Aufbau des Netzes\n",
    "4. Training\n",
    "5. Speichern des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Vorbereitung\n",
    "\n",
    "##### Modelname\n",
    "Damit verschiedene Versionen des neuronalen Netzes unterschieden werden, wird gleich zu Beginn ein eindeutiger Name für das Model definiert. Dieser Name wird sollte jeweils zu Beginn jedes Skripts identisch sein, damit konsistent mit denselben Daten gearbeitet wird.\n",
    "\n",
    "##### Bibliotheken\n",
    "Anschließend müssen unterschiedliche Bibliotheken für die Datei- und Bildverarbeitung, sowie für die Definition und den Aufbau von neuronalen Netzen mittels der Bibliothek Tensorflow geladen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "ModelNameAndVersion = \"dig-01\"\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Laden der Trainingsbilder\n",
    "Die Trainingsbilder werden aus einem Verzeichnis geladen. Da neben dem Bild auch die Klassifizierung notwendig ist, wird diese direkt im Dateinamen nach folgender Nomenklatur gespeichert:\n",
    "\n",
    "Die Bilddaten und die Klassifizierung wird in den beiden Arrays x_data (Bilddaten) und y_data (Klassifizierung) gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Festlegen der Variablen und Initialisieren der Arrays ########################\n",
    "Input_dir = 'bilder_resize'\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "\n",
    "###### Laden der Bildateien in einer Schleife über als jpeg-Bilder ##################\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "for aktfile in files:\n",
    "    img = Image.open(aktfile)                              # Laden der Bilddaten\n",
    "    data = np.array(img)\n",
    "    x_data.append(data)\n",
    "    \n",
    "    Dateiname      = os.path.basename(aktfile)             # Dateiname\n",
    "    Classification = Dateiname[0:1]                        # 1. Ziffer = Zielwert\n",
    "    if Classification == \"N\":\n",
    "        category = 10                          \n",
    "    else:\n",
    "        category = int(Classification)\n",
    "    category_vektor = tf.keras.utils.to_categorical(category, 11) # Umwandlung in Vektor\n",
    "    y_data.append(category_vektor)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Erzeugen Trainingsdaten & Testdaten\n",
    "\n",
    "##### Mischen und Zerteilung der Trainingsdaten\n",
    "Zunächst werden die geladenen Bilder über die Funktion \"shuffle\" gemischt. Durch die Verwendung von x_data und y_data gleichzeit, wird die Zuordnung im Array erhalten\n",
    "\n",
    "Anschließend werden die Bilddaten in Trainingsdaten (x/y_train) und Testdaten (x/y_test) aufgeteilt.\n",
    "\n",
    "##### Image Augmentation\n",
    "Als nächste wird der im ersten Teil schon bekannte ImageDataGenerator definiert, der die Eingangsbilder mit den verschiedenen Parametern (shift, brightness, zoom, rotation) zufällig modifiziert und dann ausgibt.\n",
    "Hier wird nun eine Batchgröße von 4 verwendet, diese hat sich in verschiedenen Netzgeometrien bewährt.\n",
    "Der Generator wird sowohl auf die Trainings- wie auch auf die Testdaten angewendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "Training_Percentage = 0.2\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size=Training_Percentage)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "### Image Augmentation\n",
    "Shift_Range = 2\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 5\n",
    "ZoomRange = 0.2\n",
    "\n",
    "### OHNE Image Augmentation\n",
    "#Shift_Range = 0\n",
    "#Brightness_Range = 0\n",
    "#Rotation_Angle = 0\n",
    "#ZoomRange = 0\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range  = [-Shift_Range, Shift_Range], \n",
    "                             height_shift_range = [-Shift_Range, Shift_Range],\n",
    "                             brightness_range   = [1-Brightness_Range, 1+Brightness_Range],\n",
    "                             zoom_range         = [1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range     = Rotation_Angle)\n",
    "Batch_Size = 4\n",
    "train_iterator      = datagen.flow(x_train, y_train, batch_size=Batch_Size)\n",
    "validation_iterator = datagen.flow(x_test,  y_test,  batch_size=Batch_Size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Definition und Aufbau des Netzes\n",
    "Das Layout besteht aus einer Abfolge von **Convolutional** und **MaxPooling** Layern. Zu Beginn kommt noch ein Layer zum Normalisieren der Eingangsdaten. Vor dem Ausgangslayer gibt es noch einen \"flachen\" Layer mit 512 Neuronen.\n",
    "\n",
    "##### Input\n",
    "* Bilder der Größe 32x20 Pixel mit 3 Farbkanalen --> input_shape = (32,20,3)\n",
    "\n",
    "##### Output\n",
    "* 11 Neuronen: Ziffern 0, 1, ..., 9 + Not-A-Number als Sonderfall\n",
    "\n",
    "#### Kompilieren\n",
    "Zum Abschluss wird hier das Netzwerk noch Kompiliert, damit es für die Verwendung verwendbar ist. Die Detailparameter hierfür findet man in der einschlägigen Literatur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss= tf.keras.losses.categorical_crossentropy, \n",
    "              optimizer= tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), \n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Training des Netzes\n",
    "Beim Training müssen die Anzahl der Trainingszyklen (Epoch_Anz) und die Größe der gleichzeitig trainierten Bilder (Batch_Size) definiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch_Anz  = 50\n",
    "history = model.fit(train_iterator, \n",
    "                    validation_data = validation_iterator, \n",
    "                    epochs          = Epoch_Anz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung der Trainingsergebnisse\n",
    "\n",
    "Nun kann man den Verlauf des Trainings visualisieren\n",
    "Dabei wird sowohl der Fehler in den Trainingsdaten, wie auch in den Testdaten aufgetragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Speichern des neuronalen Netzes\n",
    "\n",
    "Zum Abschluss wird das neuronale Netz noch für die weitere Verwendung gespeichert. Hier wird zunächst das vollständige Netz im sogenannten H5-Format gespeichert. Ein Umwandlung in das für die Programmierung im dritten Teil notwendige tflite-Format erfolgt in einem anderen Skript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## H5-Format\n",
    "model.save('saved_model/' + ModelNameAndVersion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
